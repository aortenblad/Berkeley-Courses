---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
```

###Problem 5A

```{r}


#plot of mu_hat
ggplot(data.frame(x = c(-10:10)), aes(x=x)) + 
      stat_function(fun = dnorm ,args=list(mean=0, sd=4))

#plot of sigma^2_hat
ggplot(data.frame(x = c(-10:50)), aes(x=4*x)) + 
  stat_function(fun = dchisq ,args=list(df=96))
```

###Problem 5D 

```{r}
#a)
problem_data = read.delim('~/Berkeley/Stat153/HW5/data.8.32.txt', header = FALSE, sep = "", dec = ".")
estimated_mu = mean(problem_data$V1)
estimated_second_mom = sum((problem_data$V1 - estimated_mu)^2)
estimated_S_sqrd = (1/(length(problem_data$V1))) * estimated_second_mom
estimated_mu
estimated_S_sqrd

#b) 90% CI for u and sigma^2:
n=16
alpha = 0.1
estimated_S = sqrt(estimated_S_sqrd)
estimated_mu_90_CI = c(estimated_mu - (qt(1 - alpha/2, df=n-1))*estimated_S/sqrt(n), estimated_mu + (qt(1 - alpha/2, df=n-1))*estimated_S/sqrt(n))
estimated_mu_90_CI
estimated_sigma_sqrd = ((n-1)/n) * estimated_S_sqrd
estimated_sigma_sqrd_90_CI = c(n*estimated_sigma_sqrd*(1/(qchisq(1 - alpha/2, df = n-1))), n*estimated_sigma_sqrd*(1/(qchisq(alpha/2, df = n-1))))
estimated_sigma_sqrd_90_CI

#c) 90% CI for sigma:
estimated_sigma_90_CI = sqrt(estimated_sigma_sqrd_90_CI)
estimated_sigma_90_CI
```

###Problem 5G

```{r}
#cleaning dataset
data_scores <- read.delim('~/Berkeley/Stat153/HW5/data.scores.txt', header = TRUE, sep = "", dec = ".")
df_scores <- data.frame(data_scores)
filtered_scores <- dplyr::filter(df_scores, f > 0 & m > 0)
filtered_scores[,2] <- 2*filtered_scores[,2]
clean_df <- filtered_scores[c(2,1)]

#plot histograms
hist(clean_df$m)
hist(clean_df$f)

#making boxplots
df_long = clean_df %>% gather(value=scores)
df_long  %>% ggplot(aes(y=scores)) + geom_boxplot(aes(x=key)) 
```

The boxplots reveal that the final scores had a higher median and tighter spread than the midterm scores. These scores were also seemingly more skewed than those on the midterm. Indeed, all of these observations agree with the prior histograms, where it is clear that the final was far more skewed, tighter, and with a higher median score.  


###Problem 5H

```{r}
#normal quantile plot
sample_normal = rnorm(n = 500, mean = 10, sd = 3)
qqnorm(sample_normal)

#final scores quantile plot
qqnorm(clean_df$f)
```
The plot for the normal distribution samples clearly looks linear, unlike that of the final scores, which clearly have a curvature, and look almost cubic.


###Problem 5I

```{r}
stem(clean_df$f)
stem(clean_df$f, scale=0.5)
stem(clean_df$f, scale=2)
```
I think that the one with scale 0.5 is most informative, since it allows one to most clearly get a feel for the variation in the data, along with large median and general skewness towards its higher values. 


###Problem 5J

```{r}
#a) graph data and line y = x
plot(x = clean_df$m, y=clean_df$f, type='p', )

clean_df %>% ggplot(aes(x=m, y=f)) + 
            geom_point() + 
            stat_function(fun=function(x)x, geom="line", aes(colour='y = x')) + 
            scale_colour_manual("Function", values=c('red'))
```

It clearly seems to me that more than half of the students gained from the grading scheme

```{r}
#b) - count those who gained from grading scheme
counter = 0
for (i in 1:nrow(clean_df)) {
  if(clean_df$f[i] > clean_df$m[i]) { 
    counter = counter + 1
  } else {next()}
}

counter
counter / nrow(clean_df)
```
As expected, almost 60% of the students gained from the grading scheme.



#c)
I would not use this exact line, but instead opt for one with a higher y-intercept and slightly flatter slope. Indeed, I think that doing so would allow a more even amount of students to be clustered on each side of the line, rather than the asymmetric 41% to 59% with the current line. 




